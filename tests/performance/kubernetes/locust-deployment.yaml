# Kubernetes deployment for distributed Locust load testing
# Scales to 1 million simulated users across multiple worker pods
#
# Usage:
#   kubectl apply -f locust-deployment.yaml
#   kubectl scale deployment locust-worker --replicas=50
#
# Access master UI: kubectl port-forward svc/locust-master 8089:8089

apiVersion: v1
kind: ConfigMap
metadata:
  name: locust-config
data:
  TARGET_RPS: "100000"
  TOTAL_URLS: "1000000000"
  CONCURRENT_USERS: "1000000"
  # Comma-separated list of viral short codes to test
  VIRAL_CODES: ""

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: locust-scripts
data:
  locustfile.py: |
    # Content from locustfile_distributed.py
    # In production, mount this from a ConfigMap or use a Docker image

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: locust-master
  labels:
    app: locust
    role: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: locust
      role: master
  template:
    metadata:
      labels:
        app: locust
        role: master
    spec:
      containers:
      - name: locust
        image: locustio/locust:2.20.0
        args:
          - "--master"
          - "--host=$(TARGET_HOST)"
          - "-f"
          - "/mnt/locust/locustfile_distributed.py"
        env:
          - name: TARGET_HOST
            value: "http://url-shortener-service:8080"
          - name: TARGET_RPS
            valueFrom:
              configMapKeyRef:
                name: locust-config
                key: TARGET_RPS
          - name: CONCURRENT_USERS
            valueFrom:
              configMapKeyRef:
                name: locust-config
                key: CONCURRENT_USERS
        ports:
          - containerPort: 8089
            name: web
          - containerPort: 5557
            name: master
          - containerPort: 5558
            name: master-bind
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
          - name: locust-scripts
            mountPath: /mnt/locust
      volumes:
        - name: locust-scripts
          configMap:
            name: locust-scripts

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: locust-worker
  labels:
    app: locust
    role: worker
spec:
  replicas: 10  # Scale this up for more load
  selector:
    matchLabels:
      app: locust
      role: worker
  template:
    metadata:
      labels:
        app: locust
        role: worker
    spec:
      containers:
      - name: locust
        image: locustio/locust:2.20.0
        args:
          - "--worker"
          - "--master-host=locust-master"
          - "-f"
          - "/mnt/locust/locustfile_distributed.py"
        env:
          - name: TARGET_RPS
            valueFrom:
              configMapKeyRef:
                name: locust-config
                key: TARGET_RPS
          - name: CONCURRENT_USERS
            valueFrom:
              configMapKeyRef:
                name: locust-config
                key: CONCURRENT_USERS
          - name: VIRAL_CODES
            valueFrom:
              configMapKeyRef:
                name: locust-config
                key: VIRAL_CODES
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
          - name: locust-scripts
            mountPath: /mnt/locust
      volumes:
        - name: locust-scripts
          configMap:
            name: locust-scripts

---
apiVersion: v1
kind: Service
metadata:
  name: locust-master
spec:
  selector:
    app: locust
    role: master
  ports:
    - name: web
      port: 8089
      targetPort: 8089
    - name: master
      port: 5557
      targetPort: 5557
    - name: master-bind
      port: 5558
      targetPort: 5558
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: locust-master-web
spec:
  selector:
    app: locust
    role: master
  ports:
    - port: 8089
      targetPort: 8089
  type: LoadBalancer  # External access to Locust UI

---
# HorizontalPodAutoscaler for workers
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: locust-worker-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: locust-worker
  minReplicas: 10
  maxReplicas: 100
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70

---
# PodDisruptionBudget to ensure test stability
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: locust-worker-pdb
spec:
  minAvailable: 80%
  selector:
    matchLabels:
      app: locust
      role: worker
